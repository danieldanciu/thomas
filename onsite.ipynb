{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "NQcvrsxrl1AM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdWruUl1b34R"
      },
      "outputs": [],
      "source": [
        "#! pip install pandas sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_ranking"
      ],
      "metadata": {
        "id": "SvJqTsU8Gxky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "Cmmhvtr-cH3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_ranking as tfr"
      ],
      "metadata": {
        "id": "yjZcweqOG6kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "df = pd.read_csv(BytesIO(list(uploaded.values())[0]))"
      ],
      "metadata": {
        "id": "84U-Qqugcqx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df.sample(frac = 0.8)\n",
        "df_test = df.drop(df_train.index)"
      ],
      "metadata": {
        "id": "zYe4HzCmfIcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.bind_avg.hist(bins=100)"
      ],
      "metadata": {
        "id": "myaC_MNycxJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "((df.bind_avg-df.bind_avg.mean())**2).mean()"
      ],
      "metadata": {
        "id": "imspb4jtfPVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 30\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,split=\"character\", input_shape=(1,))\n",
        "encoder.adapt(df.Sequence)\n"
      ],
      "metadata": {
        "id": "qLFcMkPJdSJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder(df.Sequence[0])"
      ],
      "metadata": {
        "id": "HqKY0dRghVKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n"
      ],
      "metadata": {
        "id": "uEtw5rSEeAim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example = encoder(df.Sequence[0]).numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "id": "hGEVcqprfpRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline LSTM Model"
      ],
      "metadata": {
        "id": "6MAw8S0mmbxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n"
      ],
      "metadata": {
        "id": "7aTbGfSMg2sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x):\n",
        "  return (x-x.mean())/x.std()\n",
        "def mse(x):\n",
        "  return ((x-x.mean())**2).mean()\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def spearman_rankcor(y_true, y_pred):\n",
        "    return (tf.py_function(\n",
        "        spearmanr, [tf.cast(y_pred, tf.float32),\n",
        "                    tf.cast(y_true, tf.float32)],\n",
        "        Tout=tf.float32))"
      ],
      "metadata": {
        "id": "S8e3dJM1ksL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mock Data"
      ],
      "metadata": {
        "id": "g9MQAzGmmUxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_data_x = 1000*[\"AAAAAAAA\",\"BBBBBB\"]\n",
        "mock_data_y = 1000*[-1.,1.]\n",
        "model.compile(loss=\"mse\",optimizer=tf.keras.optimizers.Adam(1e-3),metrics=[\"mse\",spearman_rankcor])\n",
        "model.fit(mock_data_x,mock_data_y, epochs=1000, batch_size=10)"
      ],
      "metadata": {
        "id": "A7rHW9Q2YENR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(mock_data_x)"
      ],
      "metadata": {
        "id": "2xPehjEPZDck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM with MSE loss"
      ],
      "metadata": {
        "id": "HniY0eV_mkU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mse = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model_mse.compile(loss=\"mse\",optimizer=tf.keras.optimizers.Adam(1e-4),metrics=[\"mse\",spearman_rankcor])\n",
        "model_mse.fit(df_train.Sequence,df_train.bind_avg, validation_data=(df_test.Sequence,df_test.bind_avg), epochs=100, batch_size=512)"
      ],
      "metadata": {
        "id": "czaCP6F4HC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM with ranking loss"
      ],
      "metadata": {
        "id": "e2yD2WhQmyAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwl = tfr.keras.losses.PairwiseHingeLoss()\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "# TODO: add relative weighs for loss components.\n",
        "def nested_pairwise_loss(x,y):\n",
        "  return pwl(tf.reshape(x,(1,-1)),tf.reshape(y,(1,-1))) + mse(x,y)\n"
      ],
      "metadata": {
        "id": "XZQb81Q8O-nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ranking = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_ranking.compile(loss=nested_pairwise_loss,optimizer=tf.keras.optimizers.Adam(1e-4),metrics=[\"mse\",spearman_rankcor])\n",
        "model_ranking.fit(df_train.Sequence,df_train.bind_avg, validation_data=(df_test.Sequence,df_test.bind_avg), epochs=500, batch_size=1024)"
      ],
      "metadata": {
        "id": "dG51LLveIQ13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tfr.keras.losses.PairwiseHingeLoss,optimizer=tf.keras.optimizers.Adam(1e-5),metrics=[\"mse\",spearman_rankcor])\n",
        "model.fit(df_train.Sequence,df_train.bind_avg, validation_data=(df_test.Sequence,df_test.bind_avg), epochs=10, batch_size=128)"
      ],
      "metadata": {
        "id": "Oq0ut9vTg_72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "JPWHzfMSnB1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([predictions[df.bind_avg<-3].squeeze(),predictions[df.bind_avg>-3].squeeze()],100, histtype='step', stacked=True, fill=False, density=True)"
      ],
      "metadata": {
        "id": "nBoJPC1Zp0uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model_ranking.predict(df.Sequence)\n",
        "scatter(predictions,df.bind_avg, marker='.')\n",
        "xlim(-1.02,-1.01)"
      ],
      "metadata": {
        "id": "nPgzU19UnMZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESM-2 8M model"
      ],
      "metadata": {
        "id": "c-CkhtTsm_tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers evaluate datasets requests pandas"
      ],
      "metadata": {
        "id": "CCDWUDiMnurK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"facebook/esm2_t6_8M_UR50D\"\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "train_tokenized = tokenizer(list(df_train.Sequence.values))\n",
        "test_tokenized = tokenizer(list(df_test.Sequence.values))\n",
        "train_dataset = Dataset.from_dict(train_tokenized)\n",
        "test_dataset = Dataset.from_dict(test_tokenized)\n",
        "\n",
        "train_dataset = train_dataset.add_column(\"labels\", df_train.bind_avg)\n",
        "test_dataset = test_dataset.add_column(\"labels\", df_test.bind_avg)\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "f5r9GeTSrLOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "# Declare model as single class and use for regression\n",
        "model_transformer = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=1,\n",
        "                                                           ignore_mismatched_sizes=True)"
      ],
      "metadata": {
        "id": "2fTjJ83xxCj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "tf_test_set = model.prepare_tf_dataset(\n",
        "    test_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "t28w-RcGr9vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamWeightDecay\n",
        "\n",
        "model_transformer.compile(optimizer=AdamWeightDecay(2e-5),loss=\"mse\", metrics=[\"mse\",get_spearman_rankcor])"
      ],
      "metadata": {
        "id": "h496ny1mw9M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_transformer.fit(tf_train_set, validation_data=tf_test_set, epochs=3)"
      ],
      "metadata": {
        "id": "KyBo3oHwxg3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--fvhvP1xhRU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}